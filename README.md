# E-Lab Devs â€“ Python Sitemap Crawler

Basit ama iÅŸlevsel bir **Python crawler**.  
Siteni tarar, bulduÄŸu sayfalardan **dinamik `sitemap.xml`** Ã¼retir.  
Cloudflare arkasÄ±nda Ã§alÄ±ÅŸÄ±rken bile â€œlokalden tara â†’ prod domaine yazâ€ mantÄ±ÄŸÄ±yla kanonik URLâ€™ler oluÅŸturur.

> Developed & open-sourced by **E-Lab Devs**.

---

## âœ¨ Ã–zellikler
- ğŸ” BFS tarama (linkleri takip eder, dÃ¶ngÃ¼ye girmez)
- ğŸŒ **Kanonik base**: Local/stagingâ€™den tarasan bile `<loc>` hep prod domain (Ã¶r. `https://www.elabdevs.com`)
- ğŸ§¹ HariÃ§ tutma kurallarÄ± (admin, api, assets vs.)
- ğŸ•’ `lastmod`: `HEAD` â†’ `Last-Modified` varsa kullanÄ±r, yoksa UTC now
- âš™ï¸ `.env` ile konfigÃ¼rasyon (domain, hÄ±z, limit vs.)
- ğŸ§‘â€ğŸ’» Cloudflare ile uyum (User-Agent / IP allow ile bypass)

---

## ğŸ“¦ Gereksinimler
- Python **3.9+** (Ã¶nerilen: 3.11)
- pip (gÃ¼ncel)
- (Opsiyonel) virtualenv

---

## ğŸš€ Kurulum
```bash
git clone https://github.com/elabdevs/elabdevs-crawler.git
cd elabdevs-crawler

# (opsiyonel) sanal ortam
python3 -m venv .venv
source .venv/bin/activate

pip install -r requirements.txt
cp .env.example .env
```

---

## âš™ï¸ KonfigÃ¼rasyon (.env)
```env
START_URL=http://localhost
CANONICAL_BASE=https://www.example.com
OUTPUT_PATH=/path/to/sitemap.xml

MAX_PAGES=1000
REQ_TIMEOUT=10
CRAWL_DELAY_SEC=0.2

EXCLUDE_PREFIXES=/admin,/login,/panel,/api,/uploads,/assets,/static,/storage

CRAWLER_UA=E-LabDevsCrawler/1.1 (+https://www.elabdevs.com)

CHANGEFREQ=weekly
PRIORITY=0.5
```

**Notlar:**
- `START_URL`: Cloudflareâ€™Ä± bypass eden lokal/staging adresin (Ã¶rn: `http://127.0.0.1:8080/`).
- `CANONICAL_BASE`: Sitemapâ€™te yazÄ±lacak **asÄ±l domain** (Ã¶rn: `https://www.senin-domainin.com`).
- `OUTPUT_PATH`: Ãœretilen dosyanÄ±n yolu (web root iÃ§inde olmalÄ±).
- `EXCLUDE_PREFIXES`: Sitemapâ€™e girmesini istemediÄŸin pathâ€™ler.
- `CRAWLER_UA`: Cloudflare/Firewallâ€™da allow kuralÄ± yazacaksan burada verdiÄŸin UAâ€™yÄ± kullan.

---

## â–¶ï¸ Ã‡alÄ±ÅŸtÄ±rma
```bash
python main.py
```

BaÅŸarÄ±lÄ± Ã§alÄ±ÅŸÄ±nca:
```
Toplam URL: 9
sitemap.xml yazÄ±ldÄ± -> /path/to/sitemap.xml
```

---

## ğŸ—‚ robots.txt
Arama motorlarÄ±na konumu bildir:
```
Sitemap: https://www.example.com/sitemap.xml
```

---

## â° Cron ile OtomatikleÅŸtirme
Her gece 03:00â€™te Ã§alÄ±ÅŸtÄ±rmak iÃ§in:
```bash
crontab -e
```
SatÄ±r ekle:
```
0 3 * * * /path/to/.venv/bin/python /path/to/main.py >> /var/log/sitemap_crawler.log 2>&1
```

> Ä°pucu: Crawler bittiÄŸinde Googleâ€™a ping atmak istersen, `main.py` sonunda ÅŸu GET isteÄŸini Ã§aÄŸÄ±rabilirsin:  
> `https://www.google.com/ping?sitemap=https://www.elabdevs.com/sitemap.xml`

---

## ğŸ” Cloudflare NotlarÄ± (403 gÃ¶rÃ¼rsen)
- **SeÃ§enek 1:** Crawlerâ€™Ä±n Ã§alÄ±ÅŸtÄ±ÄŸÄ± **IPâ€™yi Allow** et  
  Security â†’ *Security rules / Tools* â†’ **IP Access Rules** â†’ *Allow* (sunucu IP: `curl ifconfig.me`).
- **SeÃ§enek 2:** **User-Agent Allow**  
  Security â†’ *Security rules* â†’ *Create rule* â†’ Expression:  
  ```
  (http.user_agent contains "E-LabDevsCrawler")
  ```
  Action: **Allow**  
- **SeÃ§enek 3 (testlik):** Bot Fight Modeâ€™u geÃ§ici olarak kapat.

---

## ğŸ›  Troubleshooting
**1) `TypeError: 'type' object is not subscriptable`**  
â†’ Python < 3.9 kullanÄ±yorsun. 3.11â€™e yÃ¼kselt veya `typing.List` kullan.

**2) `pip` import hatalarÄ±**  
â†’ `pip` eski. GÃ¼ncelle:
```bash
curl -sS https://bootstrap.pypa.io/get-pip.py | python3
```

**3) `403 Forbidden`**  
â†’ Cloudflare UA/IP izinlerini ayarla.

**4) `sitemap.xml` boÅŸ**  
- `START_URL` yanlÄ±ÅŸ / HTML gelmiyor / JS ile render ediliyor olabilir.  
- `EXCLUDE_PREFIXES` Ã§ok agresif olabilir.  

**5) URLâ€™ler `localhost` Ã§Ä±kÄ±yor**  
â†’ `.env`â€™de `CANONICAL_BASE` doÄŸru mu?

---

## ğŸ“œ Lisans
**MIT** â€“ gÃ¶nlÃ¼nce kullan, forkla, geliÅŸtir.  
Â© E-Lab Devs

---

## ğŸ™Œ KatkÄ±
Pull requestâ€™ler ve issueâ€™lar aÃ§Ä±k.  
Projeyi faydalÄ± bulduysan â­ vermeyi unutma!

---

### ğŸ” Repo Description
> A simple Python-based web crawler that generates `sitemap.xml`.  
> Developed and open-sourced by **E-Lab Devs**.
